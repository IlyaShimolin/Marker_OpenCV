{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d0a6365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "# Create ChArUco board\n",
    "gridboard = aruco.CharucoBoard_create(\n",
    "        squaresX=6, \n",
    "        squaresY=8, \n",
    "        squareLength=0.04, \n",
    "        markerLength=0.02, \n",
    "        dictionary=aruco.Dictionary_get(aruco.DICT_5X5_50))\n",
    "\n",
    "img = gridboard.draw(outSize=(988, 1400))\n",
    "cv2.imwrite(\"test_charuco.jpg\", img)\n",
    "cv2.imshow('Gridboard', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16d788c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "# Create ArUco marker\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_5X5_50)\n",
    "img = aruco.drawMarker(aruco_dict, 4, 200)\n",
    "cv2.imwrite(\"test_marker4.jpg\", img)\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda28c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 valid captures\n",
      "Camera intrinsic parameters matrix:\n",
      "[[8.29978089e+03 0.00000000e+00 8.43156528e+02]\n",
      " [0.00000000e+00 1.20816386e+04 3.49463376e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "\n",
      "Camera distortion coefficients:\n",
      "[[-2.24940883e+03 -2.13844881e+00  3.11717067e+01  8.91861279e-01\n",
      "   3.18580580e-04]]\n",
      "Calibration successful. Calibration file created: CameraCalibration.pckl\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import cv2\n",
    "from cv2 import aruco\n",
    "import argparse\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "\n",
    "ARUCO_DICT=aruco.Dictionary_get(aruco.DICT_5X5_50)\n",
    "CHARUCO_BOARD = aruco.CharucoBoard_create(squaresX=6,squaresY=8,squareLength=0.04,markerLength=0.02,dictionary=ARUCO_DICT)\n",
    "\n",
    "captures=50\n",
    "#num of squares for a valid calibration image\n",
    "validresponse=20\n",
    "corners_all = []\n",
    "ids_all = [] \n",
    "image_size = None \n",
    "\n",
    "cap = cv2.VideoCapture('123.mp4')\n",
    "validCaptures = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    if ret is False:\n",
    "        break\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    corners, ids, _ = aruco.detectMarkers(\n",
    "        image=gray,\n",
    "        dictionary=ARUCO_DICT)\n",
    "    if ids is None:\n",
    "        continue\n",
    "    img = aruco.drawDetectedMarkers(image=img,corners=corners)\n",
    "    response, charuco_corners, charuco_ids = aruco.interpolateCornersCharuco(\n",
    "        markerCorners=corners,\n",
    "        markerIds=ids,\n",
    "        image=gray,\n",
    "        board=CHARUCO_BOARD)\n",
    "    if response > validresponse:\n",
    "        # Add these corners and ids to our calibration arrays\n",
    "        corners_all.append(charuco_corners)\n",
    "        ids_all.append(charuco_ids)\n",
    "        # If our image size is unknown, set it now\n",
    "        if not image_size:\n",
    "            image_size = gray.shape[::-1]\n",
    "        # Reproportion the image, maxing width or height at 1000\n",
    "        proportion = max(img.shape) / 1000.0\n",
    "        img = cv2.resize(img, (int(img.shape[1]/proportion), int(img.shape[0]/proportion)))\n",
    "        validCaptures += 1\n",
    "        if validCaptures == captures:\n",
    "            break\n",
    "cv2.destroyAllWindows()\n",
    "print(\"{} valid captures\".format(validCaptures))\n",
    "\n",
    "# Now that we've seen all of our images, perform the camera calibration\n",
    "calibration, cameraMatrix, distCoeffs, rvecs, tvecs = aruco.calibrateCameraCharuco(\n",
    "    charucoCorners=corners_all,\n",
    "    charucoIds=ids_all,\n",
    "    board=CHARUCO_BOARD,\n",
    "    imageSize=image_size,\n",
    "    cameraMatrix=None,\n",
    "    distCoeffs=None)\n",
    "\n",
    "print(\"Camera intrinsic parameters matrix:\\n{}\".format(cameraMatrix))\n",
    "print(\"\\nCamera distortion coefficients:\\n{}\".format(distCoeffs))\n",
    "\n",
    "f = open('./CameraCalibration.pckl', 'wb')\n",
    "pickle.dump((cameraMatrix, distCoeffs, rvecs, tvecs), f)\n",
    "f.close()\n",
    "\n",
    "print('Calibration successful. Calibration file created: {}'.format('CameraCalibration.pckl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af32902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "f = open('./CameraCalibration.pckl', 'rb')\n",
    "(cameraMatrix, distCoeffs, rvecs, tvecs) = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "ARUCO_PARAMETERS = aruco.DetectorParameters_create()\n",
    "ARUCO_DICT = aruco.Dictionary_get(aruco.DICT_5X5_50)\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 1280)\n",
    "cam.set(4, 720)\n",
    "\n",
    "while(cam.isOpened()):\n",
    "    ret,img = cam.read()\n",
    "    if ret == True:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMETERS)\n",
    "        img = aruco.drawDetectedMarkers(img, corners, borderColor=(0, 0, 255))\n",
    "        if ids is not None and len(ids) > 0:\n",
    "            rotation_vectors, translation_vectors, _objPoints = aruco.estimatePoseSingleMarkers(corners, 1, cameraMatrix, distCoeffs)\n",
    "            for rvec, tvec in zip(rotation_vectors, translation_vectors):\n",
    "                img = cv2.drawFrameAxes(img, cameraMatrix, distCoeffs, rvec, tvec, 0.5)\n",
    "    cv2.imshow('img',img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cam.release()\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f736de",
   "metadata": {},
   "source": [
    "# Custom marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c678bbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "cv2.imwrite(\"marker.png\", cv2.resize(np.array([\n",
    "    [0, 0,   0,   0,   0,   0,   0,   0],\n",
    "    [0, 0,   255, 0,   0,   255, 0,   0],\n",
    "    [0, 0,   255, 255, 255, 255, 255, 0],\n",
    "    [0, 255, 255, 255, 255, 255, 0,   0],\n",
    "    [0, 255, 255, 255, 255, 255, 255, 0],\n",
    "    [0, 255, 255, 255, 255, 255, 255, 0],\n",
    "    [0, 0,   0,   0,   255, 0,   255, 0],\n",
    "    [0, 0,   0,   0,   0,   0,   0,   0],\n",
    "]), (512, 512), interpolation=cv2.INTER_NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0919f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import copy\n",
    "import imutils\n",
    "import pickle\n",
    "#размер маркера\n",
    "mrk_size = 200\n",
    "minArea=20\n",
    "pi=3.14159\n",
    "len_marker=125\n",
    "#углы маркера\n",
    "edgM = np.array([\n",
    "    [0, 0],\n",
    "    [mrk_size-1, 0],\n",
    "    [mrk_size-1, mrk_size-1],\n",
    "    [0, mrk_size-1]], dtype=\"float32\")\n",
    "#пока библиотека состоит из 1 маркера                 \n",
    "dict_cust_marker=[1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
    "#определение подходящих контуров  \n",
    "def get_contour(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur=cv2.GaussianBlur(gray, (13, 13), 0) \n",
    "    ret, thresh = cv2.threshold(blur, 100, 255, cv2.THRESH_BINARY) \n",
    "    contour_list = []\n",
    "    contours,h = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    index=[]\n",
    "    polygons=[]\n",
    "    quads=[]\n",
    "    if len(contours)>0:\n",
    "        for i in h[0]:\n",
    "            if i[3]!=-1:\n",
    "                index.append(i[3])\n",
    "        for i in index:\n",
    "            polygons.append(cv2.approxPolyDP(contours[i], 3, True))\n",
    "        for i in polygons:\n",
    "            if len(i)==4 and cv2.contourArea(i)>=minArea:\n",
    "                quads.append(i) \n",
    "    return quads\n",
    "\n",
    "\n",
    "\n",
    "#расшифровка маркера\n",
    "def ident(tag):\n",
    "    num_rot=0\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            if (tag[37+i*125,37+j*125]==255):\n",
    "                n=i*2+j\n",
    "                if (n==0):\n",
    "                    num_rot=0\n",
    "                elif (n==1):\n",
    "                    num_rot=1\n",
    "                elif (n==2):\n",
    "                    num_rot=3\n",
    "                elif (n==3):\n",
    "                    num_rot=2\n",
    "    (h, w) = tag.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "    M =cv2.getRotationMatrix2D((cX, cY), num_rot*90, 1.0)\n",
    "    rotated = cv2.warpAffine(tag, M, (w, h))\n",
    "    id_code=[]\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            if (((i==0 or i==5) and (j==0 or j==5)) or ((i!=0 and i!=5) and (j!=0 and j!=5))):\n",
    "                continue\n",
    "            id_code.append(int(rotated[37+i*25,37+j*25]<225))\n",
    "    return id_code,num_rot,rotated   \n",
    "\n",
    "    \n",
    "def draw_axis(img,points,mtx,dist,num_rot):\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    imgp = np.array(points[:,0], dtype=\"float32\")\n",
    "    objp = np.array([[0.,0.,0.],\n",
    "                     [1.,0.,0.],\n",
    "                     [1.,1.,0.],\n",
    "                     [0.,1.,0.]], dtype=\"float32\")  \n",
    "    axis = np.float32([[0,0,0], [1,0,0], [0,1,0], [0,0,-1]])\n",
    "    objp = np.roll(objp, num_rot, axis=0)\n",
    "    cv2.cornerSubPix(gray,imgp,(11,11),(-1,-1),criteria)\n",
    "    _, rvecs, tvecs, inliers  = cv2.solvePnPRansac(objp, imgp, mtx, dist)\n",
    "    imgpts, _ = cv2.projectPoints(axis, rvecs, tvecs, mtx, dist)\n",
    "    imgpts = np.int32(imgpts).reshape(-1,2)\n",
    "    for i in range(3):\n",
    "            cv2.line(img,tuple(imgpts[0]),tuple(imgpts[i+1]),(255,0,0),4)\n",
    "    return img, rvecs     \n",
    "#определение угла по стержню\n",
    "def high_accuracy(tag):\n",
    "    tag1=tag[50:150,50:150]\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "    params.filterByCircularity = True;\n",
    "    params.minCircularity = 0.85;\n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "    keypoints = detector.detect(tag1)\n",
    "    pts = cv2.KeyPoint_convert(keypoints)\n",
    "    angle=[]\n",
    "    for p in pts:\n",
    "        angle.append(np.arcsin((50-p)/len_marker)*180/pi)\n",
    "    return(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a773d652",
   "metadata": {},
   "source": [
    "# Использование камеры "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da067c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 1280)\n",
    "cam.set(4, 720)\n",
    "f = open('./CameraCalibration.pckl', 'rb')\n",
    "(cameraMatrix, distCoeffs, rvecs, tvecs) = pickle.load(f)\n",
    "f.close()\n",
    "while(cam.isOpened()):\n",
    "    ret,img = cam.read()\n",
    "    if ret == False:\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    contour_list=get_contour(img)\n",
    "    if contour_list==None or contour_list==0:\n",
    "        continue\n",
    "    else:\n",
    "        decoded=[]\n",
    "        num_rot=[]\n",
    "        for i in range(len(contour_list)):\n",
    "            c_rez = contour_list[i][:, 0]\n",
    "            H_matrix, status = cv2.findHomography(c_rez,edgM)\n",
    "            tag = cv2.warpPerspective(img, H_matrix, (mrk_size, mrk_size))\n",
    "            tag = cv2.cvtColor(tag, cv2.COLOR_BGR2GRAY)\n",
    "            tag1, thresh = cv2.threshold(tag, 100, 255, cv2.THRESH_BINARY)\n",
    "            decoded,num_rot=ident(thresh)\n",
    "            \n",
    "\n",
    "            M =cv2.getRotationMatrix2D((cX, cY), -num_rot*90, 1.0)\n",
    "            rotated = cv2.warpAffine(tag, M, (w, h))\n",
    "            \n",
    "            a=high_accuracy(rotated)\n",
    "               \n",
    "            ##\n",
    "            if a != []:\n",
    "                text= \"x = %d[deg],y = %d[deg]\"%(a[0][0],a[0][1])\n",
    "                fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontScale = 1\n",
    "                thickness = 1\n",
    "                size, baseLine = cv2.getTextSize(text, fontFace, fontScale, thickness)\n",
    "                cv2.putText(img, text, (0, size[1]), fontFace, fontScale,(0, 0, 255), thickness)\n",
    "            ##\n",
    "        if len(contour_list)>0:\n",
    "            for i in contour_list:\n",
    "                img=draw_axis(img,i,cameraMatrix,distCoeffs)\n",
    "        \n",
    "    \n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2961f748",
   "metadata": {},
   "source": [
    "# Использование экрана ПК\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38807022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from mss import mss\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "f = open('CameraCalibration.pckl', 'rb')\n",
    "(cameraMatrix, distCoeffs, rvecs, tvecs) = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "mon = {'top': 400, 'left': 400, 'width': 500, 'height': 500}\n",
    "\n",
    "sct = mss()\n",
    "\n",
    "while 1:\n",
    "    sct.get_pixels(mon)\n",
    "    img = np.array(Image.frombytes('RGB', (sct.width, sct.height), sct.image))\n",
    "    \n",
    "    contour_list=get_contour(img)\n",
    "    correct_contour=[]\n",
    "    if contour_list==None or contour_list==0:\n",
    "        continue\n",
    "    else:\n",
    "        decode=[]\n",
    "        num_rot=[]\n",
    "        for i in range(len(contour_list)):\n",
    "            c_rez = contour_list[i][:, 0]\n",
    "            H_matrix, status = cv2.findHomography(c_rez,edgM)\n",
    "            tag = cv2.warpPerspective(img, H_matrix, (mrk_size, mrk_size))\n",
    "            tag = cv2.cvtColor(tag, cv2.COLOR_BGR2GRAY)\n",
    "            tag1, thresh = cv2.threshold(tag, 100, 255, cv2.THRESH_BINARY)\n",
    "            code,num,rotated=ident(thresh)\n",
    "            decode.append(code)\n",
    "            num_rot.append(num)\n",
    "            if code==dict_cust_marker:\n",
    "                correct_contour.append(contour_list[i])\n",
    "                a=high_accuracy(rotated)\n",
    "                if a != []:\n",
    "                    text= \"x = %d[deg],y = %d[deg]\"%(a[0][0],a[0][1])\n",
    "                    #text = \"Rotation: %d[deg], Code:\" % (90 * rot90)  + ''.join(str(e) for e in decoded)\n",
    "                    fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    fontScale = 0.5\n",
    "                    thickness = 1\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    size1, baseLine1 = cv2.getTextSize(text, fontFace, fontScale, thickness)\n",
    "                    text_coord = (5,baseLine1+5)\n",
    "                    cv2.rectangle(img,(text_coord[0]-5, text_coord[1]+baseLine1),(size1[0]+100, 0),(255, 255, 255),-1)\n",
    "                    cv2.putText(img, text, (0, size1[1]), fontFace, fontScale,(0, 0, 255), thickness)\n",
    "             \n",
    "            ##\n",
    "\n",
    "            ##\n",
    "        if len(correct_contour)>0:\n",
    "            indx=0\n",
    "            for i in correct_contour:\n",
    "                img,rvecs=draw_axis(img,i,cameraMatrix,distCoeffs,num_rot[indx])\n",
    "                indx=indx+1\n",
    "                if rvecs.size > 0:\n",
    "                    a=[]\n",
    "                    for i in range(len(rvecs)):\n",
    "                        a.append(int(rvecs[i][0]*180/pi))\n",
    "                    #text= \"x = %d[deg],y = %d[deg],z = %d[deg]\"%(an[0],an[1],a[2])\n",
    "                    text= \"z = %d[deg]\"%(a[2])\n",
    "                    fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    fontScale = 0.5\n",
    "                    thickness = 1\n",
    "                    \n",
    "                    size, baseLine = cv2.getTextSize(text, fontFace, fontScale, thickness)\n",
    "                    text_coord = (0,baseLine*3+5)\n",
    "                    #cv2.rectangle(img,(baseLine1, size[1]*2-5),(size[0]+5, size[1]*3+5),(255, 0, 255),-1)\n",
    "                    \n",
    "                    cv2.putText(img, text, (baseLine1+220, size1[1]), fontFace, fontScale,(0, 0, 255), thickness)\n",
    "                    \n",
    "                    #                    size, baseLine = cv2.getTextSize(text, fontFace, fontScale, thickness)\n",
    "                    #text_coord = (0,baseLine*3+5)\n",
    "                    #cv2.rectangle(img,(0, size[1]*2-5),(size[0]+5, size[1]*3+5),(255, 255, 255),-1)\n",
    "                    \n",
    "                    #cv2.putText(img, text, (0, size[1]*3), fontFace, fontScale,(0, 0, 255), thickness)\n",
    "        #img = cv2.drawContours(img, contour_list,  -1, (0, 255, 0), 2)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('test', img)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9cc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv-env",
   "language": "python",
   "name": "opencv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
